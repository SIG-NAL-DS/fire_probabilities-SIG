{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "from scipy.interpolate import griddata\n",
    "import subprocess\n",
    "from google.cloud import storage\n",
    "import ee\n",
    "from rasterio.transform import from_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "* ACCESS1-0\n",
    "* BCC-CSM1-1\n",
    "* BCC-CSM1-1-M\n",
    "* BNU-ESM\n",
    "* CanESM2\n",
    "* CCSM4\n",
    "* CESM1-BGC\n",
    "* CESM1-CAM5\n",
    "* CMCC-CM\n",
    "* CNRM-CM5\n",
    "* CSIRO-Mk3-6-0\n",
    "* FGOALS-G2\n",
    "* FIO-ESM\n",
    "* GFDL-CM3\n",
    "* GFDL-ESM2G\n",
    "* GFDL-ESM2M\n",
    "* GISS-E2-H-CC\n",
    "* GISS-E2-R\n",
    "* GISS-E2-R-CC\n",
    "* HadGEM2-AO\n",
    "* HadGEM2-CC\n",
    "* HadGEM2-ES\n",
    "* INMCM4\n",
    "* IPSL-CM5A-MR\n",
    "* IPSL-CM5B-LR\n",
    "* MIROC-ESM\n",
    "* MIROC-ESM-CHEM\n",
    "* MIROC5\n",
    "* MPI-ESM-LR\n",
    "* MPI-ESM-MR\n",
    "* MRI-CGCM3\n",
    "* NorESM1-M\n",
    "\n",
    "**Variables**\n",
    "- albedo\n",
    "- baseflow\n",
    "- del_SWE\n",
    "- ET\n",
    "- latent\n",
    "- longwave_net\n",
    "- pet_natveg\n",
    "- precip\n",
    "- Qair\n",
    "- rainfall\n",
    "- rel_Humid\n",
    "- runoff\n",
    "- sensible\n",
    "- shortwave_in\n",
    "- shortwave_net\n",
    "- snow_melt\n",
    "- snowfall\n",
    "- soilMoist1\n",
    "- soilMoist2\n",
    "- soilMoist3\n",
    "- sublimation_net\n",
    "- SWE\n",
    "- Tair\n",
    "- Wdew\n",
    "- windspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def download_file_from_ftp(ftp_path, local_destination=None):\n",
    "    \"\"\"\n",
    "    Download a specific file from an FTP server.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ftp_path: str\n",
    "        Full FTP path to the file (e.g., \"ftp://server/path/to/file\").\n",
    "    local_destination: str\n",
    "        Destination folder to save the file locally. Defaults to the current working directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Full path to the downloaded file on the local machine.\n",
    "    \"\"\"\n",
    "    # Parse the FTP server and file path\n",
    "    ftp_server = ftp_path.split('/')[2]  # Extract server from URL\n",
    "    file_path = '/'.join(ftp_path.split('/')[3:])  # Extract file path on server\n",
    "    file_name = os.path.basename(file_path)  # Extract file name\n",
    "    \n",
    "    # Set the local destination\n",
    "    if local_destination is None:\n",
    "        local_destination = os.getcwd()\n",
    "    if not os.path.exists(local_destination):\n",
    "        os.makedirs(local_destination)\n",
    "    \n",
    "    local_file_path = os.path.join(local_destination, file_name)\n",
    "\n",
    "    # Connect to FTP and download file\n",
    "    ftp = ftplib.FTP(ftp_server)\n",
    "    ftp.login()\n",
    "    print(f\"Connected to {ftp_server}. Downloading {file_name}...\")\n",
    "    \n",
    "    with open(local_file_path, 'wb') as local_file:\n",
    "        ftp.retrbinary(f\"RETR {file_path}\", local_file.write)\n",
    "    \n",
    "    ftp.quit()\n",
    "    print(f\"Download complete. File saved to: {local_file_path}\")\n",
    "    \n",
    "    return local_file_path\n",
    "\n",
    "    \n",
    "ftp_url = \"ftp://gdo-dcp.ucllnl.org/pub/dcp/archive/cmip5/loca_hydro/LOCA_VIC_dpierce_2017-02-28/CanESM2/vic_output.historical.netcdf/ET.1990.v0.nc\"\n",
    "local_folder = \"./downloaded_files\"  # Adjust as needed\n",
    "download_file_from_ftp(ftp_url, local_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "import os\n",
    "\n",
    "def download_model_files(model, year, variable, scenario=\"rcp85\", local_destination=None):\n",
    "    \"\"\"\n",
    "    Download a specific NetCDF file for a model and year from the FTP server.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: str\n",
    "        Model name (e.g., \"CESM1-BGC\", \"CanESM2\").\n",
    "    year: int\n",
    "        Year of the desired file.\n",
    "    variable: str\n",
    "        Variable to download (e.g., \"ET\").\n",
    "    scenario: str\n",
    "        Climate scenario for future projections (default: \"rcp85\"). \"rcp45\"\n",
    "        Used for years after 2005.\n",
    "    local_destination: str\n",
    "        Destination folder to save files locally. Defaults to current working directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    local_file_path: str\n",
    "        Path to the downloaded file or None if the file was not found.\n",
    "    \"\"\"\n",
    "    ftp_server = \"gdo-dcp.ucllnl.org\"\n",
    "    base_path = \"/pub/dcp/archive/cmip5/loca_hydro/LOCA_VIC_dpierce_2017-02-28\"\n",
    "\n",
    "    # Set local destination\n",
    "    if local_destination is None:\n",
    "        local_destination = os.getcwd()\n",
    "    if not os.path.exists(local_destination):\n",
    "        os.makedirs(local_destination)\n",
    "\n",
    "    # Connect to FTP server\n",
    "    ftp = ftplib.FTP(ftp_server)\n",
    "    ftp.login()\n",
    "    print(f\"Connected to {ftp_server}.\")\n",
    "\n",
    "    # Determine folder based on year\n",
    "    if year <= 2005:\n",
    "        folder_path = f\"{base_path}/{model}/vic_output.historical.netcdf\"\n",
    "    else:\n",
    "        folder_path = f\"{base_path}/{model}/vic_output.{scenario}.netcdf\"\n",
    "\n",
    "    # File name for the specific year\n",
    "    file_name = f\"{variable}.{year}.v0.nc\"\n",
    "    remote_file_path = f\"{folder_path}/{file_name}\"\n",
    "\n",
    "    # Local file path\n",
    "    local_file_path = os.path.join(local_destination, file_name)\n",
    "\n",
    "    try:\n",
    "        # Attempt to download the file\n",
    "        print(f\"Downloading {file_name} from {remote_file_path}...\")\n",
    "        with open(local_file_path, 'wb') as local_file:\n",
    "            ftp.retrbinary(f\"RETR {remote_file_path}\", local_file.write)\n",
    "        print(f\"Successfully downloaded {file_name}.\")\n",
    "    except ftplib.error_perm as e:\n",
    "        print(f\"Error: File {file_name} not found on the server. ({e})\")\n",
    "        local_file_path = None\n",
    "    finally:\n",
    "        # Close the FTP connection\n",
    "        ftp.quit()\n",
    "        print(\"FTP connection closed.\")\n",
    "\n",
    "    return local_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to gdo-dcp.ucllnl.org.\n",
      "Downloading ET.2006.v0.nc from /pub/dcp/archive/cmip5/loca_hydro/LOCA_VIC_dpierce_2017-02-28/CanESM2/vic_output.rcp85.netcdf/ET.2006.v0.nc...\n",
      "Successfully downloaded ET.2006.v0.nc.\n",
      "Download process complete.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" model_name = \"CanESM2\"  # Adjust as needed\n",
    "start = 2005\n",
    "end = 2006\n",
    "variable= 'ET'\n",
    "#output_folder = \"./downloaded_files\"  # Specify your output folder\n",
    "\n",
    "download_model_files(model_name, start, end,variable) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Open the .nc file\n",
    "file_path = \"./downloaded_files/ET.1990.v0.nc\"  # Adjust to your file path\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(ds)\n",
    "\n",
    "# Select the variable \"ET\"\n",
    "et = ds[variable]\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: {'driver': 'netCDF', 'dtype': 'float32', 'nodata': 1.0000000150474662e+30, 'width': 960, 'height': 490, 'count': 365, 'crs': None, 'transform': Affine(0.0625, 0.0, -126.0,\n",
      "       0.0, -0.0625, 54.0), 'blockxsize': 960, 'blockysize': 490, 'tiled': False}\n",
      "CRS: None\n",
      "Transform: | 0.06, 0.00,-126.00|\n",
      "| 0.00,-0.06, 54.00|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Width, Height: 960 490\n",
      "Bounds: BoundingBox(left=-126.0, bottom=23.375, right=-66.0, top=54.0)\n",
      "Resolution: (0.0625, 0.0625)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open the NetCDF file with rasterio\n",
    "nc_path = r\"C:\\Users\\bsf31\\Documents\\data\\fire_probabilities\\ET.2005.v0.nc\"\n",
    "\n",
    "with rasterio.open(f\"NETCDF:{nc_path}\") as src:\n",
    "    print(\"Profile:\", src.profile)  # Metadata similar to a .tif\n",
    "    print(\"CRS:\", src.crs)  # Coordinate reference system\n",
    "    print(\"Transform:\", src.transform)  # Affine transform (origin, resolution, rotation)\n",
    "    print(\"Width, Height:\", src.width, src.height)  # Number of columns and rows\n",
    "    print(\"Bounds:\", src.bounds)  # Extent (minx, miny, maxx, maxy)\n",
    "    print(\"Resolution:\", src.res)  # Cell size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF saved to ./ET_monthly_range.tif\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Resample daily data to monthly averages\n",
    "monthly_avg = et.resample(Time=\"1ME\").mean(dim=\"Time\")\n",
    "\n",
    "monthly_range = monthly_avg.max(dim=\"Time\") - monthly_avg.min(dim=\"Time\")  # Shape: (Lat, Lon)\n",
    "lat = ds[\"Lat\"].values\n",
    "lon = ds[\"Lon\"].values\n",
    "# Handle 1D or 2D lat/lon arrays\n",
    "if len(lat.shape) == 1 and len(lon.shape) == 1:\n",
    "    # 1D lat and lon\n",
    "    lon2d, lat2d = np.meshgrid(lon, lat)\n",
    "elif len(lat.shape) == 2 and len(lon.shape) == 2:\n",
    "    # 2D lat and lon\n",
    "    lat2d, lon2d = lat, lon\n",
    "else:\n",
    "    raise ValueError(\"Lat and Lon dimensions are incompatible. Check their shapes.\")\n",
    "\n",
    "# Create the interpolation grid\n",
    "lon_interp = np.linspace(lon2d.min(), lon2d.max(), monthly_range.shape[1])\n",
    "lat_interp = np.linspace(lat2d.min(), lat2d.max(), monthly_range.shape[0])\n",
    "lon_mesh, lat_mesh = np.meshgrid(lon_interp, lat_interp)\n",
    "\n",
    "# Flatten the original lat/lon and data values for interpolation\n",
    "lat_lon_points = np.array([lat2d.ravel(), lon2d.ravel()]).T\n",
    "monthly_range_flat = monthly_range.values.ravel()\n",
    "\n",
    "# Perform interpolation to the regular grid\n",
    "grid_data = griddata(lat_lon_points, monthly_range_flat, (lat_mesh, lon_mesh), method=\"linear\")\n",
    "\n",
    "# Flip the grid vertically for correct orientation\n",
    "grid_data_flipped = np.flipud(grid_data)\n",
    "\n",
    "nodata_value = -9999\n",
    "# Replace NaN values in the grid with the NoData value\n",
    "grid_data_flipped = np.where(np.isnan(grid_data_flipped), nodata_value, grid_data_flipped)\n",
    "\n",
    "# Save as GeoTIFF\n",
    "transform = from_bounds(\n",
    "    lon_interp.min(), lat_interp.min(),\n",
    "    lon_interp.max(), lat_interp.max(),\n",
    "    grid_data_flipped.shape[1], grid_data_flipped.shape[0]\n",
    ")\n",
    "\n",
    "output_tif = \"./ET_monthly_range.tif\"\n",
    "# Define the NoData value\n",
    "\n",
    "\n",
    "with rasterio.open(\n",
    "    output_tif,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=grid_data_flipped.shape[0],\n",
    "    width=grid_data_flipped.shape[1],\n",
    "    count=1,\n",
    "    dtype=grid_data_flipped.dtype,\n",
    "    crs=\"EPSG:4326\",\n",
    "    transform=transform,\n",
    "    nodata=nodata_value\n",
    ") as dst:\n",
    "    dst.write(grid_data_flipped, 1)\n",
    "\n",
    "print(f\"GeoTIFF saved to {output_tif}\")\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to gdo-dcp.ucllnl.org.\n",
      "Downloading ET.2005.v0.nc from /pub/dcp/archive/cmip5/loca_hydro/LOCA_VIC_dpierce_2017-02-28/CanESM2/vic_output.historical.netcdf/ET.2005.v0.nc...\n",
      "Successfully downloaded ET.2005.v0.nc.\n",
      "FTP connection closed.\n",
      "GeoTIFF saved to ./output_tifs\\ET_monthly_range_2005.tif\n",
      "Connected to gdo-dcp.ucllnl.org.\n",
      "Downloading ET.2006.v0.nc from /pub/dcp/archive/cmip5/loca_hydro/LOCA_VIC_dpierce_2017-02-28/CanESM2/vic_output.rcp85.netcdf/ET.2006.v0.nc...\n",
      "Successfully downloaded ET.2006.v0.nc.\n",
      "FTP connection closed.\n",
      "GeoTIFF saved to ./output_tifs\\ET_monthly_range_2006.tif\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # Configuration\n",
    "model_name = \"CanESM2\"\n",
    "start_year = 2005\n",
    "end_year = 2006\n",
    "variable = \"ET\"\n",
    "output_folder = \"./output_tifs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through years\n",
    "for year in range(start_year, end_year + 1):\n",
    "    # Step 1: Download NetCDF file\n",
    "    file_path = download_model_files(model_name, year, variable)\n",
    "    \n",
    "    # Step 2: Open the NetCDF file\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    et = ds[variable]\n",
    "\n",
    "    # Step 3: Resample daily data to monthly averages\n",
    "    monthly_avg = et.resample(Time=\"1ME\").mean(dim=\"Time\")\n",
    "\n",
    "    # Step 4: Calculate the range of monthly averages\n",
    "    monthly_range = monthly_avg.max(dim=\"Time\") - monthly_avg.min(dim=\"Time\")  # Shape: (Lat, Lon)\n",
    "\n",
    "    # Step 5: Extract lat/lon and handle 1D or 2D arrays\n",
    "    lat = ds[\"Lat\"].values\n",
    "    lon = ds[\"Lon\"].values\n",
    "\n",
    "    if len(lat.shape) == 1 and len(lon.shape) == 1:\n",
    "        lon2d, lat2d = np.meshgrid(lon, lat)\n",
    "    elif len(lat.shape) == 2 and len(lon.shape) == 2:\n",
    "        lat2d, lon2d = lat, lon\n",
    "    else:\n",
    "        raise ValueError(\"Lat and Lon dimensions are incompatible. Check their shapes.\")\n",
    "\n",
    "    # Step 6: Create the interpolation grid\n",
    "    lon_interp = np.linspace(lon2d.min(), lon2d.max(), monthly_range.shape[1])\n",
    "    lat_interp = np.linspace(lat2d.min(), lat2d.max(), monthly_range.shape[0])\n",
    "    lon_mesh, lat_mesh = np.meshgrid(lon_interp, lat_interp)\n",
    "\n",
    "    # Step 7: Interpolate the data to a regular grid\n",
    "    lat_lon_points = np.array([lat2d.ravel(), lon2d.ravel()]).T\n",
    "    monthly_range_flat = monthly_range.values.ravel()\n",
    "    grid_data = griddata(lat_lon_points, monthly_range_flat, (lat_mesh, lon_mesh), method=\"linear\")\n",
    "\n",
    "    # Flip the grid vertically for correct orientation\n",
    "    grid_data_flipped = np.flipud(grid_data)\n",
    "\n",
    "    # Step 8: Replace NaN values with NoData value\n",
    "    nodata_value = -9999\n",
    "    grid_data_flipped = np.where(np.isnan(grid_data_flipped), nodata_value, grid_data_flipped)\n",
    "\n",
    "    # Step 9: Save the result as a GeoTIFF\n",
    "    transform = from_bounds(\n",
    "        lon_interp.min(), lat_interp.min(),\n",
    "        lon_interp.max(), lat_interp.max(),\n",
    "        grid_data_flipped.shape[1], grid_data_flipped.shape[0]\n",
    "    )\n",
    "\n",
    "    output_tif = os.path.join(output_folder, f\"{variable}_monthly_range_{year}.tif\")\n",
    "    with rasterio.open(\n",
    "        output_tif,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=grid_data_flipped.shape[0],\n",
    "        width=grid_data_flipped.shape[1],\n",
    "        count=1,\n",
    "        dtype=grid_data_flipped.dtype,\n",
    "        crs=\"EPSG:4326\",\n",
    "        transform=transform,\n",
    "        nodata=nodata_value\n",
    "    ) as dst:\n",
    "        dst.write(grid_data_flipped, 1)\n",
    "\n",
    "    print(f\"GeoTIFF saved to {output_tif}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_year(model, year, variable, scenario, output_folder, gcp_bucket, ee_path):\n",
    "    # Step 1: Download .nc File\n",
    "    nc_file_path = download_model_files(model, year, variable, scenario, output_folder)\n",
    "\n",
    "    if not nc_file_path:\n",
    "        print(f\"No .nc file for {year}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Convert .nc to .tif\n",
    "    ds = xr.open_dataset(nc_file_path)\n",
    "    et = ds[variable]\n",
    "    monthly_avg = et.resample(Time=\"1MS\").mean(dim=\"Time\")\n",
    "    monthly_range = monthly_avg.max(dim=\"Time\") - monthly_avg.min(dim=\"Time\")\n",
    "    \n",
    "    # Handle lat/lon\n",
    "    lat, lon = ds[\"Lat\"].values, ds[\"Lon\"].values\n",
    "    lon2d, lat2d = np.meshgrid(lon, lat)\n",
    "    lon_interp = np.linspace(lon2d.min(), lon2d.max(), monthly_range.shape[1])\n",
    "    lat_interp = np.linspace(lat2d.min(), lat2d.max(), monthly_range.shape[0])\n",
    "    lon_mesh, lat_mesh = np.meshgrid(lon_interp, lat_interp)\n",
    "    lat_lon_points = np.array([lat2d.ravel(), lon2d.ravel()]).T\n",
    "    monthly_range_flat = monthly_range.values.ravel()\n",
    "    grid_data = griddata(lat_lon_points, monthly_range_flat, (lat_mesh, lon_mesh), method=\"linear\")\n",
    "    grid_data_flipped = np.flipud(np.where(np.isnan(grid_data), -9999, grid_data))\n",
    "\n",
    "    transform = from_bounds(\n",
    "        lon_interp.min(), lat_interp.min(), lon_interp.max(), lat_interp.max(),\n",
    "        grid_data_flipped.shape[1], grid_data_flipped.shape[0]\n",
    "    )\n",
    "    tif_file = os.path.join(output_folder, f\"{variable}_monthly_range_{year}.tif\")\n",
    "    with rasterio.open(\n",
    "        tif_file, \"w\", driver=\"GTiff\", height=grid_data_flipped.shape[0],\n",
    "        width=grid_data_flipped.shape[1], count=1, dtype=grid_data_flipped.dtype,\n",
    "        crs=\"EPSG:4326\", transform=transform, nodata=-9999\n",
    "    ) as dst:\n",
    "        dst.write(grid_data_flipped, 1)\n",
    "    print(f\"GeoTIFF saved to {tif_file}\")\n",
    "\n",
    "    # Delete .nc File\n",
    "    os.remove(nc_file_path)\n",
    "    print(f\"Deleted .nc file: {nc_file_path}\")\n",
    "\n",
    "    # Step 3: Save as COG\n",
    "    cog_file = tif_file.replace(\".tif\", \"_cog.tif\")\n",
    "    cog_cmd = f'gdal_translate {tif_file} {cog_file} -co TILED=YES -co COPY_SRC_OVERVIEWS=YES -co COMPRESS=LZW'\n",
    "    subprocess.run(cog_cmd, shell=True)\n",
    "    os.remove(tif_file)\n",
    "    print(f\"COG created and original GeoTIFF deleted: {cog_file}\")\n",
    "\n",
    "    # Step 4: Upload to GCP\n",
    "    cp_cmd = f\"gsutil cp {cog_file} gs://{gcp_bucket}/{os.path.basename(cog_file)}\"\n",
    "    subprocess.run(cp_cmd, shell=True)\n",
    "    print(f\"Uploaded COG to GCP: {cog_file}\")\n",
    "\n",
    "    # Step 5: Register in Earth Engine\n",
    "    ee_image = ee.Image.loadGeoTIFF(f\"gs://{gcp_bucket}/{os.path.basename(cog_file)}\")\n",
    "    ee_image = ee_image.set(\n",
    "        \"system:time_start\", ee.Date(f\"{year}-01-01\").millis(),\n",
    "        \"system:time_end\", ee.Date(f\"{year}-12-31\").millis(),\n",
    "        \"model\", model,\n",
    "        \"variable\", variable,\n",
    "        \"scenario\", scenario\n",
    "    )\n",
    "    asset_id = f\"projects/{PROJECT_ID}/assets/{ee_path}/{variable}_monthly_range_{year}\"\n",
    "    ee.data.createAsset({\"type\": \"IMAGE_COLLECTION\"}, ee_path, allowExisting=True)\n",
    "    ee.batch.Export.image.toAsset(\n",
    "        image=ee_image,\n",
    "        description=f\"{variable}_{year}\",\n",
    "        assetId=asset_id,\n",
    "        region=ee_image.geometry().bounds(),\n",
    "        scale=5000,\n",
    "        maxPixels=1e13,\n",
    "    ).start()\n",
    "    print(f\"Registered in Earth Engine: {asset_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "output_folder = \"./output\"\n",
    "gcp_bucket = \"my-gcp-bucket\"\n",
    "ee_path = \"my-ee-collection-path\"\n",
    "start_year, end_year = 2005, 2006\n",
    "model = \"CanESM2\"\n",
    "variable = \"ET\"\n",
    "scenario = \"rcp85\"\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "# Process each year\n",
    "for year in range(start_year, end_year + 1):\n",
    "    process_year(model, year, variable, scenario, output_folder, gcp_bucket, ee_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "output_folder = \"./output\"\n",
    "gcp_bucket = \"my-gcp-bucket\"\n",
    "ee_path = \"my-ee-collection-path\"\n",
    "start_year, end_year = 2005, 2006\n",
    "model = \"CanESM2\"\n",
    "variable = \"ET\"\n",
    "scenario = \"rcp85\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF saved to C:\\Users\\bsf31\\Documents\\data\\fire_probabilities\\ET_monthly_range_2005.tif\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download .nc File\n",
    "nc_file_path = r\"C:\\Users\\bsf31\\Documents\\data\\fire_probabilities\\ET.2005.v0.nc\"\n",
    "\n",
    "\n",
    "# Step 2: Open NetCDF and extract variable\n",
    "ds = xr.open_dataset(nc_file_path)\n",
    "et = ds[\"ET\"]\n",
    "\n",
    "# Compute monthly statistics\n",
    "monthly_avg = et.resample(Time=\"1MS\").mean(dim=\"Time\")\n",
    "monthly_range = monthly_avg.max(dim=\"Time\") - monthly_avg.min(dim=\"Time\")\n",
    "\n",
    "# Get spatial dimensions\n",
    "lat = ds[\"Lat\"].values  # Latitude\n",
    "lon = ds[\"Lon\"].values  # Longitude\n",
    "data_array = monthly_range.values  # Extract numpy array\n",
    "\n",
    "\n",
    "data_array = np.flipud(data_array)\n",
    "lat = lat[::-1]  # Reverse to match flipped array\n",
    "\n",
    "# Get resolution (Check if lat/lon are regularly spaced)\n",
    "res_x = abs(lon[1] - lon[0])\n",
    "res_y = abs(lat[1] - lat[0])\n",
    "\n",
    "# Adjust bounds to account for pixel edges (NetCDF may store cell centers)\n",
    "lat_min, lat_max = lat.min() - (res_y / 2), lat.max() + (res_y / 2)\n",
    "lon_min, lon_max = lon.min() - (res_x / 2), lon.max() + (res_x / 2)\n",
    "\n",
    "# Define transformation using corrected bounds\n",
    "transform = from_bounds(lon_min, lat_min, lon_max, lat_max, data_array.shape[1], data_array.shape[0])\n",
    "\n",
    "# Check for CRS in NetCDF (If available, use it instead of EPSG:4326)\n",
    "if \"spatial_ref\" in ds.variables:\n",
    "    crs = ds.spatial_ref.attrs.get(\"crs\", \"EPSG:4326\")  # Get CRS if present\n",
    "else:\n",
    "    crs = \"EPSG:4326\"  # Default assumption\n",
    "\n",
    "# Define output GeoTIFF file path\n",
    "tif_file = os.path.join(r'C:\\Users\\bsf31\\Documents\\data\\fire_probabilities', f\"ET_monthly_range_2005.tif\")\n",
    "\n",
    "# Create GeoTIFF using rasterio\n",
    "with rasterio.open(\n",
    "    tif_file, \"w\", driver=\"GTiff\",\n",
    "    height=data_array.shape[0], width=data_array.shape[1],\n",
    "    count=1, dtype=data_array.dtype,\n",
    "    crs=crs, transform=transform, nodata=-9999\n",
    ") as dst:\n",
    "    dst.write(data_array, 1)\n",
    "\n",
    "print(f\"GeoTIFF saved to {tif_file}\")\n",
    "\n",
    "# Close dataset\n",
    "ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
